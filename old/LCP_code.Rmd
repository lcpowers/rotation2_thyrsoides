---
title: 'Time-lagged IPM'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Packages
```{r packages, message=FALSE}
rm(list=ls())

library(tidyverse)
library(nlme)
library(MASS)
```

Reading in data
```{r wrangle_data}
dataf = data.frame(read.table("ct.ipm.txt",header=T))

# attach(dataf)
# detach(dataf)

tmp=order(site[ros==1]) # Method for keeping things in the same order

size.t.all=log(nl.t*ll.t)[ros==1][tmp] # Calculate plant size in year t

size.t1.all=log(nl.t1*ll.t1)[ros==1][tmp] # Calculate plant size in year t+1

flow.all=flow[ros==1][tmp] # Logical vector for plants for 1 rosette: 1 = flowered

surv.all=surv[ros==1][tmp] # Logical vector for survival: 1 = survived

site.all=site[ros==1][tmp] # Site information

# Unsure where/how these are used
site.code.l=c("FU","SP")
pch.code=c(19,1)

# Unsure where/how these are used
all.sizes=c(size.t.all[flow.all==0],size.t1.all[year.t==2005])
all.site=c(site.all[flow.all==0],site.all[year.t==2005])	
```

Fitting models
```{r growth}

# Size in year t of plants that didn't flower
size.t=size.t.all[flow.all==0]

# Size in year t + 1 of plants that didn't flower
size.t1=size.t1.all[flow.all==0]

# Site vector for plants that didn't flower
site.s=site.all[flow.all==0]

# Creates logical filter for incomplete cases of these three arrays (treating them like a table)
test=complete.cases(size.t,size.t1,site.s)

# Filter using the above logical filter
size.t=size.t[test]
size.t1=size.t1[test]
site.s=site.s[test]

# check whether variance structure is needed
fit.grow.gls.1<-gls(size.t1~size.t+site.s, # Same in all
                    na.action=na.omit, # Same in all
                    weight=varExp(form=~fitted(.)|site.s), # Fitted and Size as random effect?
                    method="ML"); # Same in all
# summary(fit.grow.gls.1)

fit.grow.gls<-gls(size.t1~size.t+site.s,
                  na.action=na.omit,
                  weight=varExp(form=~fitted(.)), # Fitted
                  method="ML");
# summary(fit.grow.gls)

fit.grow.gls.0<-gls(size.t1~size.t+site.s,
                    na.action=na.omit, 
                    method="ML");
# summary(fit.grow.gls.0)

anova(fit.grow.gls.0,fit.grow.gls,fit.grow.gls.1) 

# check whether intercept estimate for habitat is needed
fit.grow.gls.0<-gls(size.t1~size.t, # No site
                    na.action=na.omit,
                    weight=varExp(form=~fitted(.)|site.s),
                    method="ML");
fit.grow.gls.1<-gls(size.t1~size.t+site.s, # Site as independent variable
                    na.action=na.omit,
                    weight=varExp(form=~fitted(.)|site.s),
                    method="ML");
fit.grow.gls.2<-gls(size.t1~size.t*site.s, # Size and site as interaction term
                    na.action=na.omit,
                    weight=varExp(form=~fitted(.)|site.s),
                    method="ML");

anova(fit.grow.gls.0,fit.grow.gls.1,fit.grow.gls.2)

# Refit model with size and site main effects,and site specific decreasing variance 
fit.grow.gls<-gls(size.t1~site.s+size.t-1,
                  na.action=na.omit,
                  weight=varExp(form=~fitted(.)|site.s),
                  method="ML");

summary(fit.grow.gls)
intervals(fit.grow.gls)

# Growth intercepts
g.intercepts=fit.grow.gls$coef[1:2]

# Growth slopes
g.slopes=rep(fit.grow.gls$coef[3],2)


var.exp.coef=fit.grow.gls$modelStruct$varStruct  
sigma.g=fit.grow.gls$sigma

```

Plot growth
```{r plot_growth}

par(mfrow=c(2,2),
    mar=c(3,3,1,2)+0.1,
    bty="l", # Box type
    pty="s", # Plot region type
    cex.main=1, # Main title size
    cex.axis=1, # Axis text size
    cex.lab=1, # Axis label size
    tck=0.02, # Tick mark length
    mgp=c(2, 0.3 ,0)) ; # Margin lines

plot(size.t,size.t1,
     type="n",
     xlab="Plant size year t",
     ylab="Plant size year t+1",
     xlim=c(2,10),ylim=c(2,10))

for(i in 1:2){
  points(size.t[site.s==site.code.l[i]],size.t1[site.s==site.code.l[i]],pch=pch.code[i])
  abline(g.intercepts[i],g.slopes[i],lty=i)
  abline(0,1,lty=3)
}

text(2.3,10,labels="a)")
legend(7,4.8, 
       c("FU: n=735", "SP: n=357"), 
       pch=c(19,1),lty=c(1,2),
       bty="n",
       xjust=0)

```

```{r flowering}

# 
flow.s=flow.all[order(size.t.all)]; length(flow.s)
site.s=site.all[order(size.t.all)]; length(site.s)
size.t=size.t.all[order(size.t.all)]; length(size.t)

store.size.flow=size.t[flow.s==1]
store.site.flow=site.s[flow.s==1]

fit.flow.1=glm(flow.s~size.t*site.s,family=binomial)
fit.flow=glm(flow.s~size.t+site.s,family=binomial)
fit.flow.0=glm(flow.s~size.t,family=binomial)

anova(fit.flow.0,fit.flow,fit.flow.1,test="Chisq")

fit.flow=glm(flow.s~site.s/size.t-1,family=binomial)

f.intercepts=fit.flow$coef[1:2]
f.slopes=c(fit.flow$coef[3:4])

site.flow.SE=summary(fit.flow)$coef[5:6]

```

```{r plot_flowering}
plot(size.t,flow.s,
     type="n",
     xlab="Plant size year t",
     ylab="Probability of flowering (year t+1)",
     xlim=c(2,10))

n.size<-seq(2,10,length=1000) 

for(i in 1:2){ 
  ncuts<-50 
  reps<-ceiling(length(size.t[site.s==site.code.l[i]])/ncuts) 
  c.size<-gl(ncuts,reps,length=length(size.t[site.s==site.code.l[i]])) 
  pflow<-as.numeric(sapply(split(flow.s[site.s==site.code.l[i]],c.size),mean,na.rm=T)) 
  msize<-as.numeric(sapply(split(size.t[site.s==site.code.l[i]],c.size),mean,na.rm=T)) 
  points(msize,pflow,pch=pch.code[i]) 
  fitted<-exp(f.intercepts[i]+f.slopes[i]*n.size)/ (1+exp(f.intercepts[i]+f.slopes[i]*n.size)) 
  points(n.size,fitted,type="l",lty=i)
}

text(2.3,1.0,labels="b)")
legend(2, 0.35, 
       c("FU: n=827", "SP: n=746"), 
       pch=c(19,1),lty=c(1,2),
       bty="n",
       xjust=0)
```

```{r survival}
surv.s=surv.all[order(size.t.all)]
site.s=site.all[order(size.t.all)]
size.t=size.t.all[order(size.t.all)]

fit.surv.1=glm(surv.s~size.t*site.s,family=binomial)
fit.surv=glm(surv.s~size.t+site.s,family=binomial)
fit.surv.0=glm(surv.s~size.t,family=binomial)

anova(fit.surv.0,fit.surv,fit.surv.1,test="Chisq")

fit.surv=glm(surv.s~site.s/size.t-1,family=binomial)

s.intercepts=fit.surv$coef[1:2]
s.slopes=c(fit.surv$coef[3:4])
```

```{r plot_survival}
plot(size.t,surv.s,
     type="n",
     xlab="Plant size year t",
     ylab="Probability of survival to year t+1", 
     xlim=c(2,10))

n.size<-seq(2,10,length=1000) 

for(i in 1:2){ 
  ncuts<-50 
  reps<-ceiling(length(size.t[site.s==site.code.l[i]])/ncuts) 
  c.size<-gl(ncuts,reps,length=length(size.t[site.s==site.code.l[i]])) 
  psurv<-as.numeric(sapply(split(surv.s[site.s==site.code.l[i]],c.size),mean,na.rm=T)) 
  msize<-as.numeric(sapply(split(size.t[site.s==site.code.l[i]],c.size),mean,na.rm=T)) 
  points(msize,psurv,pch=pch.code[i]) 
  fitted<-exp(s.intercepts[i]+s.slopes[i]*n.size)/ (1+exp(s.intercepts[i]+s.slopes[i]*n.size)) 
  points(n.size,fitted,type="l",lty=i)
}

text(2.3,1.0,labels="c)")
legend(7,0.35, 
       c("FU: n=827", "SP: n=746"), 
       pch=c(19,1),lty=c(1,2),
       bty="n",
       xjust=0)
```

```{r fecundity}
IPM.fecundity=data.frame(read.table("CT.IPM.fecundity.txt",header=T))

# unbrowsed individuals
size.t.f <- IPM.fecundity$size.t[IPM.fecundity$brows.t1==0]
site.t.f =  IPM.fecundity$site[IPM.fecundity$brows.t1==0]
si.t1.f <- IPM.fecundity$si.t1[IPM.fecundity$brows.t1==0]
nl.t.f <- IPM.fecundity$nl.t[IPM.fecundity$brows.t1==0]

fit.fec=lm(log(si.t1.f)~site.t.f+size.t.f-1)
```

```{r plot_fecundity}
plot(size.t.f,log(si.t1.f),type="n",xlab="Plant size year t",ylab="Viable seeds (log scale) year t+1",pch=19,xlim=c(2,10),ylim=c(2,10))

for(i in 1:2){
  points(size.t.f[site.t.f==site.code.l[i]],log(si.t1.f)[site.t.f==site.code.l[i]],pch=pch.code[i])
  abline(fit.fec$coef[i],fit.fec$coef[3],lty=i)
}

text(2.3,10,labels="d)")
legend(7,4.75,c("FU: n=25", "SP: n=28"),pch=c(19,1),lty=c(1,2),bty="n",xjust=0)
```

Seedling sizes
```{r seedlingsizes}

IPM.seedlings=data.frame(read.table("CT.IPM.seedlings.txt",header=T))

seedlings.size.t=IPM.seedlings$size.t[IPM.seedlings$site!="JU"]

seedlings.site=IPM.seedlings$site[IPM.seedlings$site!="JU"]

tmp=order(seedlings.site)

seedlings.size.t=seedlings.size.t[tmp]

seedlings.site=seedlings.site[tmp]

fit.seedlings=lm(seedlings.size.t~seedlings.site-1)

summary(fit.seedlings)

size.all.plus.seedlings=c(all.sizes,IPM.seedlings$size.t[IPM.seedlings$site!="JU" & IPM.seedlings$year.t!=2003])
site.all.plus.seedlings=c(site.all,IPM.seedlings$site[IPM.seedlings$site!="JU" & IPM.seedlings$year.t!=2003])

IPM.establishment=data.frame(read.table("IPM.establishment.data.txt",header=T))

tmp=order(IPM.establishment$site)

p.est.site=IPM.establishment$site[tmp]
p.est.seeds.t=IPM.establishment$seeds.t[tmp]
p.est.seedlings=IPM.establishment$sdl.t1[tmp]

est.p.est= sapply(split(p.est.seedlings,p.est.site),sum)/sapply(split(p.est.seeds.t,p.est.site),sum)

```

Collect parameters
```{r collect_parameters}
minsize<-1
maxsize<-12

# Global variables for midpoint rule approximation 
# n.big.matrix is the number of mesh points for size, n.age is the number of age classes. 
n.big.matrix = 250; n.age = 50; n=n.big.matrix

L= minsize; U= maxsize;

# boundary points b and mesh points y
b = L+c(0:n)*(U-L)/n; y = 0.5*(b[1:n]+b[2:(n+1)]);

# step size for midpoint rule, see equations 4 and 5
h = y[2]-y[1]


store.p.vec=array(NA,dim=c(12,2))

p.vec.names<-rep(NA,12)
p.vec<-rep(0,12);

for(i in 1:2){
  
  p.vec[1]<- s.intercepts[i]			; p.vec.names[1]<-"1st survival param";
  p.vec[2]<- s.slopes[i]				; p.vec.names[2]<-"2nd survival param";
  p.vec[3]<- f.intercepts[i]			; p.vec.names[3]<-"1st flow param    ";
  p.vec[4]<- f.slopes[i]				; p.vec.names[4]<-"2nd flow param    ";
  p.vec[5]<- g.intercepts[i]			; p.vec.names[5]<-"ag                ";
  p.vec[6]<- g.slopes[i]				; p.vec.names[6]<-"bg                ";
  p.vec[7]<- sigma.g^2				; p.vec.names[7]<-"sigma2 growth     ";
  p.vec[8]<- fit.fec$coef[i]  			; p.vec.names[8]<-"intercept seeds   ";
  p.vec[9]<- fit.fec$coef[3]	 		; p.vec.names[9]<-"slope seeds       ";
  p.vec[10]<- fit.seedlings$coef[i]		; p.vec.names[10]<-"mean kids size   ";
  p.vec[11]<- summary(fit.seedlings)$sigma^2	; p.vec.names[11]<-"sigma2 kids size ";
  p.vec[12]<- var.exp.coef[i]			; p.vec.names[12]<-"growth variance parameter ";
  
  store.p.vec[,i]=p.vec
  
}

```

## Part II
Compute the kernel component functions from the fitted models

```{r kernel_component}

sx<-function(x,params) {
  u<-exp(params[2]*x+params[1]);
  return(u/(1+u));
}

fx<-function(x,params) {
  u<-exp(params[3]+params[4]*x)
  return(u/(1+u))
}

gxy<-function(x,y,params) {
  mux<-params[5]+params[6]*x;
  sigmax2<-(params[7])*exp(2*(params[12]*mux))
  sigmax<-sqrt(sigmax2);
  fac1<-sqrt(2*pi)*sigmax;
  fac2<-((y-mux)^2)/(2*sigmax2);
  return(exp(-fac2)/fac1);
}

pxy<-function(x,y,params) { return(sx(x,params)*(1-fx(x,params))*gxy(x,y,params)) }

fxy<-function(x,y,params) {
  nkids<-p.est*exp(params[8]+params[9]*x);
  kidsize.mean<- params[10];
  kidsize.var<- params[11]; 
  fac1<-sqrt(2*pi)*sqrt(kidsize.var);
  fac2<-((y-kidsize.mean)^2)/(2*kidsize.var);
  f<-sx(x,params)*fx(x,params)*nkids*exp(-fac2)/fac1;
  return(f);
}

```

Big matrix
The 'big matrix' M of size n x n
```{r bigmatrix}

bigmatrix<-function(n,params) {
  # upper and lower integration limits
  L<-minsize; U<-maxsize;
  
  # boundary points b and mesh points y
  b<-L+c(0:n)*(U-L)/n;
  y<-0.5*(b[1:n]+b[2:(n+1)]);
  
  # construct the matrix
  I<-diag(n);
  P<-t(outer(y,y,pxy,params=params))
  B<-t(outer(y,y,fxy,params=params))
  M=array(0,dim=c(2*n,2*n))
  M[1:n,1:n]=P*(U-L)/n
  M[1:n,(n+1):(2*n)]=B*(U-L)/n
  M[(n+1):(2*n),1:n]=diag(n)
  K<-M; 
  P<-(U-L)*P/n;
  B<-(U-L)*B/n;
  return(list(matrix=M,kernel=K,meshpts=y,Pmatrix=P,Bmatrix=B,Imatrix=I)); 
}


R0.calc<-function(n,params){
  M<-bigmatrix(n,params);
  if (any(is.na(M$matrix))){
    ave.R0=NA;
    lam=NA;
    T=NA;
  } else{
    N<-solve(M$Imatrix-M$Pmatrix);
    R<- M$Bmatrix %*% N
    ave.R0<-Re(eigen(R)$values[1]);
    lam<-Re(eigen(M$matrix)$values[1]);
    T=log(ave.R0)/log(lam)
  }
  
  return(list(lam=lam,ave.R0=ave.R0,T=T))
}

R0.betas<-function(x){
  p.vec[3]<-x;
  nR0<-R0.calc(n.big.matrix,p.vec)
  return(nR0$ave.R0)
}
```

Calculation: Mean generation time
```{r calcT}
gen.time=rep(NA,2)

for(i in 1:2){
  #if(i==1) p.est= 8.604605e-05 else p.est=0.0001655622  # assuming dd-reg
  if(i==1) p.est= est.p.est[1] else p.est=est.p.est[2]   # actual
  p.vec=store.p.vec[,i]
  tmp=R0.calc(n.big.matrix,p.vec)
  gen.time[i]=tmp$T
  cat("Site ",i," lambda=",tmp$lam," R0=",tmp$ave.R0," Generation time=",tmp$T,"\n")
  cat("ESS intercept ",optimize(R0.betas,c(-100,10),maximum=T,tol=0.01)$maximum,"\n")
}
```

Calculation: ESS
```{r calcESS}

n.test<-100
R0.beta<-array(NA,dim=c(n.test,2));
lam.beta<-array(NA,dim=c(n.test,2));
ESS=rep(NA,2)

```

Plot ESS (Figure 6)
```{r plotESS}
# win.graph()
par(mfrow=c(2,2), mar=c(3,3,1,2)+0.1, bty="l",pty="s", cex.main=1, cex.axis=1, cex.lab=1, tck=0.02, mgp=c(2, 0.3 ,0)) ;

for(i in 1:2){
  p.vec=store.p.vec[,i]
  #if(i==1) p.est= 8.604605e-05 else p.est=0.0001655622  # assuming dd-reg
  if(i==1) p.est= est.p.est[1] else p.est=est.p.est[2]   # actual
  if(i==1) beta.flow<-seq(-100,0,length=n.test) else beta.flow<-seq(-50,0,length=n.test);
  
  for(beta.test in 1:n.test){
    p.vec[3]<-beta.flow[beta.test];
    nR0<-R0.calc(n.big.matrix,p.vec)
    R0.beta[beta.test,i]<-nR0$ave.R0
    lam.beta[beta.test,i]<-nR0$lam
    cat(beta.flow[beta.test],"  ",nR0$ave.R0,"  ",nR0$lam,"\n")
  }
  
  ESS[i]<-beta.flow[R0.beta[,i]==max(R0.beta[,i])]
  
  plot(beta.flow,R0.beta[,i],type="n",xlab=expression("Intercept of flowering function " * italic(beta * scriptstyle(0))),
       ylab=expression(italic("R"*scriptstyle(0))))
  min.R0=min(R0.beta[,i]); max.R0=max(R0.beta[,i])
  mean.m2se=fit.flow$coef[i]-2*site.flow.SE[i]
  mean.p2se=fit.flow$coef[i]+2*site.flow.SE[i]
  
  polygon(c(mean.m2se,mean.p2se,mean.p2se,mean.m2se),c(min.R0,min.R0,max.R0,max.R0), col="grey90",border=0)
  points(beta.flow,R0.beta[,i],type="l")
  abline(h=1)
  points(beta.flow[R0.beta[,i]==max(R0.beta[,i])],max(R0.beta[,i]),pch=19)
  abline(v=fit.flow$coef[i])
  #abline(v=beta.flow[R0.beta==max(R0.beta)])
  
  # if (i==1) text(locator(1),"a)") else text(locator(1),"c)")
  
  plot(beta.flow,lam.beta[,i],type="n",xlab=expression("Intercept of flowering function " * italic(beta * scriptstyle(0))),
       ylab=expression(italic(lambda)))
  min.R0=min(lam.beta[,i]);max.R0=max(lam.beta[,i])
  mean.m2se=fit.flow$coef[i]-2*site.flow.SE[i]
  mean.p2se=fit.flow$coef[i]+2*site.flow.SE[i]
  
  polygon(c(mean.m2se,mean.p2se,mean.p2se,mean.m2se),c(min.R0,min.R0,max.R0,max.R0), col="grey90",border=0)
  points(beta.flow,lam.beta[,i],type="l")
  abline(h=1)
  abline(v=fit.flow$coef[i])
  points(beta.flow[lam.beta[,i]==max(lam.beta[,i])],max(lam.beta[,i]),pch=19)
  
  # if (i==1) text(locator(1),"b)") else text(locator(1),"d)")
}

```

```{r}
#============================================================================================#
#	Constructing the component matrices and their transposes 
#============================================================================================#


# Put all component matrices into 3-dimensional arrays 
P<-array(NA,dim=c(n.big.matrix,n.big.matrix)) #P[j,i,a] will be h*P_{a-1}(x_j,x_i)
B<-array(NA,dim=c(n.big.matrix,n.big.matrix)) #B[j,i,a] will be h*F_{a-1}(x_j,x_i)

stable.dist=array(NA,dim=c(n,n.age,2)); lam.stable.age=rep(NA,2); 

for(i in 1:2){
  p.vec=store.p.vec[,i]
  if(i==1) p.est= est.p.est[1] else p.est=est.p.est[2]               #actual
  P<-h*t(outer(y,y,pxy,params=p.vec))
  B<-h*t(outer(y,y,fxy,params=p.vec))
  
  
  #============================================================================================#
  #	Model iteration functions  
  #============================================================================================#
  
  
  Nt=matrix(0,n.big.matrix,n.age); Nt1=Nt; Nt2=Nt	# population now and next year 
  iteration=function(Nt1,Nt){
    for(age in 2:n.age){
      Nt2[,age]=P%*%Nt1[,age-1]
    }
    Nt2[,1]=0; 
    
    for(age in 1:n.age){
      Nt2[,1]=Nt2[,1]+B%*%Nt[,age]
    }
    return(Nt2)
  }
  
  #============================================================================================#
  #	Start using the model 
  #============================================================================================#
  
  
  # Estimate lambda and w by iterating unperturbed matrix  
  Nt1=matrix(1,n.big.matrix,n.age); 
  Nt=Nt1
  qmax=1000; lam=1; tol=1.e-8; 
  while(qmax>tol) {
    Nt2=iteration(Nt1,Nt);
    qmax=sum(abs(Nt2-lam*Nt1));  
    lam=sum(Nt2)/sum(Nt1); 
    
    Nt=Nt1
    Nt1=Nt2
    
    tot=sum(Nt1+Nt2)
    
    Nt=Nt/tot
    Nt1=Nt1/tot
    
    cat(lam,qmax,"\n");
  } 
  
  stable.dist[,,i]=Nt/sum(Nt); lam.stable.age[i]=lam; 	
  
}

```


```{r}
#============================================================================# 
#  Calculation: Stable distribution and size-dependent total elasticity 
#============================================================================# 

stable.dist.flow=stable.dist

p.surv.flow=sx(y,p.vec)*fx(y,p.vec)

for(i in 1:2){
  for(age in 1:n.age){
    stable.dist.flow[,age,i]=stable.dist[,age,i]*p.surv.flow
  }
}

for(i in 1:2){
  stable.dist.flow[,,i]=stable.dist.flow[,,i]/(sum(stable.dist.flow[,,i]))
}

dataf=data.frame(read.table("ipm.saf.data.txt",header=T))
attach(dataf)

flow.age=age.05[flo.05==1]
flow.site=as.numeric(site[flo.05==1])
age=age.05
site=as.numeric(site)

stable.dist.age=array(NA,dim=c(n.age,2))
stable.dist.age.flow=array(NA,dim=c(n.age,2))

```

```{r}
#============================================================================# 
#  Plot: Stable age distribution (see Fig. 2)
#============================================================================# 

win.graph()
par(mfrow=c(2,2), mar=c(3,3,1,2)+0.1, bty="l",pty="s", cex.main=1, cex.axis=1, cex.lab=1, tck=0.02, mgp=c(2, 0.3 ,0)) ;

for(i in 1:2){
  hist(age[site==i],breaks=seq(0,50,3),freq=F,col="grey",main="",xlab="Age (years)", ylim=c(0,0.2))
  stable.dist.age[,i]=apply(stable.dist[,,i],2,sum)
  points(0:(n.age-1),stable.dist.age[,i],type="l")
  # if (i==1) text(locator(1),"a)") else text(locator(1),"c)")
  
  hist(flow.age[flow.site==i],breaks=seq(0,50,3),freq=F,col="grey",main="",xlab="Age (years)",ylim=c(0,0.20))
  stable.dist.age.flow[,i]=apply(stable.dist.flow[,,i],2,sum)
  points(0:(n.age-1),stable.dist.age.flow[,i],type="l")
  # if (i==1) text(locator(1),"b)") else text(locator(1),"d)")
}

mean.age.f=rep(NA,2)
mean.size.f=rep(NA,2)

for(i in 1:2){
  mean.age.f[i] <-sum((1:(n.age))*apply(stable.dist.flow[,,i],2,sum))-1;
  cat("Mean flowering age",mean.age.f[i],"\n")
  mean.size.f[i]<-sum(exp(y)*apply(stable.dist.flow[,,i],1,sum));
  cat("Mean flowering size",mean.size.f[i],"\n")
}

stable.dist.size=array(NA,dim=c(n.big.matrix,2))
stable.dist.size.flow=array(NA,dim=c(n.big.matrix,2))
```

```{r}
#============================================================================# 
#  Plot: Stable size distribution (see Fig. 3)
#============================================================================# 

win.graph()
par(mfrow=c(2,2), mar=c(3,3,1,2)+0.1, bty="l",pty="s", cex.main=1, cex.axis=1, cex.lab=1, tck=0.02, mgp=c(2, 0.3 ,0)) ;

for(i in 1:2){
  hist(size.all.plus.seedlings[site.all.plus.seedlings==i],freq=T,col="grey",main="",xlab="Plant size",breaks=seq(1,10.5,0.5))
  stable.dist.size[,i]=sum(!is.na(size.all.plus.seedlings[site.all.plus.seedlings==i]))*apply(stable.dist[,,i],1,sum)/(y[2]-y[1])/2
  points(y,stable.dist.size[,i],type="l")
  # if (i==1) text(locator(1),"a)") else text(locator(1),"c)")
  
  hist(store.size.flow[store.site.flow==site.code.l[i]],freq=T,col="grey",main="",xlab="Plant size",breaks=seq(2,9.5,0.5))
  stable.dist.size.flow[,i]=sum(!is.na(store.size.flow[store.site.flow==site.code.l[i]]))*apply(stable.dist.flow[,,i],1,sum)/(y[2]-y[1])/2
  points(y,stable.dist.size.flow[,i],type="l")
  # if (i==1) text(locator(1),"b)") else text(locator(1),"d)")
}
```

```{r}
#============================================================================# 
#  iterate model with time lag
#============================================================================#

stable.dist.tl=array(0,dim=c(n,2))
lam.stable.tl=rep(NA,2)
b = L+c(0:n)*(U-L)/n; y = 0.5*(b[1:n]+b[2:(n+1)]);
h = y[2]-y[1]

for(i in 1:2){
  p.vec=store.p.vec[,i]
  if(i==1) p.est= est.p.est[1] else p.est=est.p.est[2]               #actual
  P<-h*t(outer(y,y,pxy,params=p.vec))
  B<-h*t(outer(y,y,fxy,params=p.vec))
  
  qmax=1000
  
  Nt=matrix(1/n,n); Nt1=Nt/2;  # population now, next year and the one after
  
  while(qmax>1e-10) {
    Nt2=P%*%Nt1+B%*%Nt
    qmax=sum(abs(Nt2-lam*Nt1));  
    lam=sum(Nt2)/sum(Nt1); 
    Nt=Nt1;
    Nt1=Nt2;
    tot=sum(Nt+Nt1)
    Nt=Nt/tot
    Nt1=Nt1/tot
  } 
  stable.dist.tl[,i]=Nt/sum(Nt); lam.stable.tl[i]=lam; 
}

lam.stable.age
lam.stable.tl

```

```{r}
#============================================================================# 
#  Calculation: sensitivity and elasticity by perturbation P matrix
#============================================================================# 


sen.big.P<-array(NA,dim=c(n,n)) 	#array to store the results 
elas.big.P<-array(NA,dim=c(n,n,2)) 

for(i in 1:2){
  p.vec=store.p.vec[,i]
  if(i==1) p.est= est.p.est[1] else p.est=est.p.est[2]               #actual
  
  P<-h*t(outer(y,y,pxy,params=p.vec))
  B<-h*t(outer(y,y,fxy,params=p.vec))
  
  
  for(row in 1:n) {		# loop over y values 
    # choose x* to maximize e(y,x) for this y value, by scanning across the row    
    big.one=which(P[row,]*stable.dist.tl[,i]==max(P[row,]*stable.dist.tl[,i])); 
    
    # perturb the kernel up and down near (y,x*)
    delta=0.1*h*P[row,big.one];
    Pup=P; Pup[row,big.one] = P[row,big.one]+delta/h;
    Pdown=P; Pdown[row,big.one] = P[row,big.one]-delta/h;  
    
    qmax=1; lamup=1; lamdown=1; 
    Nt.up<-stable.dist.tl[,i]; Nt1.up<-stable.dist.tl[,i]
    Nt.down<-stable.dist.tl[,i]; Nt1.down<-stable.dist.tl[,i]
    
    while(qmax>1e-10) {
      Nt2.up=Pup%*%Nt1.up+B%*%Nt.up
      qmax=sum(abs(Nt2.up-lamup*Nt1.up));  
      lamup=sum(Nt2.up)/sum(Nt1.up); 
      
      Nt.up=Nt1.up;
      Nt1.up=Nt2.up;
      tot=sum(Nt.up+Nt1.up)
      Nt.up=Nt.up/tot
      Nt1.up=Nt1.up/tot
      
      Nt2.down=Pdown%*%Nt1.down+B%*%Nt.down
      
      qmax=qmax+sum(abs(Nt2.down-lamdown*Nt1.down));  
      lamdown=sum(Nt2.down)/sum(Nt1.down); 
      
      Nt.down=Nt1.down;
      Nt1.down=Nt2.down;
      tot=sum(Nt.down+Nt1.down)
      Nt.down=Nt.down/tot
      Nt1.down=Nt1.down/tot
      
      #cat(lamup,lamdown,qmax,"\n");
    } 
    
    
    sen.big.row<-(lamup-lamdown)/(2*delta) #sensitivity for perturbation at (y,x*)
    sen.big.P[row,]<-(stable.dist.tl[,i]/stable.dist.tl[,i][big.one])*sen.big.row #sensitivity at other x's 
    cat(row,big.one,lamup,lamdown," sens=",sen.big.row, "\n")
  }
  
  elas.big.P[,,i]=(P/h)*sen.big.P/lam.stable.tl[i];
  
}

sum(elas.big.P[,,1]*h*h)
sum(elas.big.P[,,2]*h*h)

```


```{r}
#============================================================================# 
#  Calculation: sensitivity and elasticity by perturbation B matrix
#============================================================================# 


sen.big.B<-array(NA,dim=c(n,n)) 	#array to store the results 
elas.big.B<-array(NA,dim=c(n,n,2)) 

for(i in 1:2){
  p.vec=store.p.vec[,i]
  if(i==1) p.est= est.p.est[1] else p.est=est.p.est[2]               #actual
  
  P<-h*t(outer(y,y,pxy,params=p.vec))
  B<-h*t(outer(y,y,fxy,params=p.vec))
  
  for(row in 1:n) {		# loop over y values 
    # choose x* to maximize e(y,x) for this y value, by scanning across the row    
    big.one=which(B[row,]*stable.dist.tl[,i]==max(B[row,]*stable.dist.tl[,i])); 
    
    # perturb the kernel up and down near (y,x*)
    delta=0.1*h*B[row,big.one];
    Bup=B; Bup[row,big.one] = B[row,big.one]+delta/h;
    Bdown=B; Bdown[row,big.one] = B[row,big.one]-delta/h;  
    
    qmax=1; lamup=1; lamdown=1; 
    Nt.up<-stable.dist.tl[,i]; Nt1.up<-stable.dist.tl[,i]
    Nt.down<-stable.dist.tl[,i]; Nt1.down<-stable.dist.tl[,i]
    
    while(qmax>1e-10) {
      Nt2.up=P%*%Nt1.up+Bup%*%Nt.up
      qmax=sum(abs(Nt2.up-lamup*Nt1.up));  
      lamup=sum(Nt2.up)/sum(Nt1.up); 
      
      Nt.up=Nt1.up;
      Nt1.up=Nt2.up;
      tot=sum(Nt.up+Nt1.up)
      Nt.up=Nt.up/tot
      Nt1.up=Nt1.up/tot
      
      Nt2.down=P%*%Nt1.down+Bdown%*%Nt.down
      
      qmax=qmax+sum(abs(Nt2.down-lamdown*Nt1.down));  
      lamdown=sum(Nt2.down)/sum(Nt1.down); 
      
      Nt.down=Nt1.down;
      Nt1.down=Nt2.down;
      tot=sum(Nt.down+Nt1.down)
      Nt.down=Nt.down/tot
      Nt1.down=Nt1.down/tot
      
      #cat(lamup,lamdown,qmax,"\n");
    } 
    
    sen.big.row<-(lamup-lamdown)/(2*delta) #sensitivity for perturbation at (y,x*)
    sen.big.B[row,]<-(stable.dist.tl[,i]/stable.dist.tl[,i][big.one])*sen.big.row #sensitivity at other x's 
    cat(row,big.one," sens=",sen.big.row, "\n")
  }
  
  elas.big.B[,,i]=2*(B/h)*sen.big.B/lam.stable.tl[i];
  
}

sum(elas.big.B[,,1]*h*h)+sum(elas.big.P[,,1]*h*h)
sum(elas.big.B[,,2]*h*h)+sum(elas.big.P[,,2]*h*h)


```

```{r}
#============================================================================# 
#  Plot: elasticity (see Fig 5)
#============================================================================# 


# win.graph()
par(mfrow=c(2,2), mar=c(3,3,1,2)+0.1, bty="l",pty="s", cex.main=1, cex.axis=1, cex.lab=1, tck=0.02, mgp=c(2, 0.3 ,0)) ;

zmax=max(elas.big.P,elas.big.B)

image(y,y,t(elas.big.P[,,1]),xlab="Plant size year t",ylab="Plant size year t+1",col=grey(1:300/300),gamma=0.2,zlim=c(0,1.1*zmax));
contour(y,y,t(elas.big.P[,,1]),add=T,cex=3,levels = c(0.01,0.05,0.1,0.15,0.2,0.25,0.3));
# text(locator(1),"a)",col="white")

image(y,y,t(elas.big.B[,,1]),xlab="Plant size year t-1",ylab="Plant size year t+1",col=grey(1:300/300),gamma=0.2,zlim=c(0,1.1*zmax));
contour(y,y,t(elas.big.B[,,1]),add=T,cex=3,levels = c(0.01,0.05,0.1,0.15,0.2,0.25,0.3));
# text(locator(1),"b)",col="white")

image(y,y,t(elas.big.P[,,2]),xlab="Plant size year t",ylab="Plant size year t+1",col=grey(1:300/300),gamma=0.2,zlim=c(0,1.1*zmax));
contour(y,y,t(elas.big.P[,,2]),add=T,cex=3,levels = c(0.01,0.05,0.1,0.15,0.2,0.25,0.3));
# text(locator(1),"c)",col="white")

image(y,y,t(elas.big.B[,,2]),xlab="Plant size year t-1",ylab="Plant size year t+1",col=grey(1:300/300),gamma=0.2,zlim=c(0,1.1*zmax));
contour(y,y,t(elas.big.B[,,2]),add=T,cex=3,levels = c(0.01,0.05,0.1,0.15,0.2,0.25,0.3));
# text(locator(1),"d)",col="white")
```


```{r}
#============================================================================# 
#  Calculation: new big matrix approximation
#============================================================================# 


M.tl=array(0,dim=c(2*n,2*n))
lam.stable.bm=rep(NA,2)
R0.stable.bm=rep(NA,2)

for(i in 1:2){
  p.vec=store.p.vec[,i]
  if(i==1) p.est= est.p.est[1] else p.est=est.p.est[2]              #actual
  if(i==1) p.vec[3]=-58.67228 else p.vec[3]= -26.25266              #actual
  
  P<-h*t(outer(y,y,pxy,params=p.vec))
  B<-h*t(outer(y,y,fxy,params=p.vec))
  
  M.tl[1:n,1:n]=P
  M.tl[1:n,(n+1):(2*n)]=B
  M.tl[(n+1):(2*n),1:n]=diag(n)
  
  lam.stable.bm[i]=Re(eigen(M.tl)$values[1]);
  
  #R0
  M.P=array(0,dim=c(2*n,2*n))
  M.B=array(0,dim=c(2*n,2*n))
  
  M.P[1:n,1:n]=P
  M.P[(n+1):(2*n),1:n]=diag(n)
  
  M.B[1:n,(n+1):(2*n)]=B
  
  
  N<-solve(diag(2*n)-M.P);
  R<- M.B %*% N
  R0.stable.bm[i]<-Re(eigen(R)$values[1]);
  
  T.stable.mb <-log(R0.stable.bm)/log(lam.stable.bm)	# Generation time
}


lam.stable.bm	# Lambda
R0.stable.bm	# Net reproductive rate
T.stable.mb 	# Generation time
```


```{r}
#==================================================================
#	Simulate Lambda, R0 and T with varying p.est
#==================================================================


seq.start <- 0.00001
seq.end <- 0.001
seq.by <- 0.00001
p.est.seq <- seq(seq.start,seq.end,by=seq.by)
n.p.est <- length(p.est.seq)

p.est.FU <- 0.00016
p.est.SP <- 0.00078

Res.p.est <- matrix(0,n.p.est,8)
dimnames(Res.p.est) <- list(1:n.p.est,c("p.est","p.est","l.FU","l.SP","Ro.FU","Ro.SP","T.FU","T.SP"))

#new big matrix approximation

M.tl=array(0,dim=c(2*n,2*n))
lam.stable.bm=rep(NA,2)
R0.stable.bm=rep(NA,2)

for (k in 1:n.p.est){
  for(i in 1:2){
    p.est= p.est.seq[k]
    p.vec=store.p.vec[,i]
    P<-h*t(outer(y,y,pxy,params=p.vec))
    B<-h*t(outer(y,y,fxy,params=p.vec))
    M.tl[1:n,1:n]=P
    M.tl[1:n,(n+1):(2*n)]=B
    M.tl[(n+1):(2*n),1:n]=diag(n)
    lam.stable.bm=Re(eigen(M.tl)$values[1]);
    
    # R0
    M.P=array(0,dim=c(2*n,2*n))
    M.B=array(0,dim=c(2*n,2*n))
    M.P[1:n,1:n]=P
    M.P[(n+1):(2*n),1:n]=diag(n)
    M.B[1:n,(n+1):(2*n)]=B
    N<-solve(diag(2*n)-M.P);
    R<- M.B %*% N
    R0.stable.bm<-Re(eigen(R)$values[1]);
    
    # Generation time
    T.stable.bm <-log(R0.stable.bm)/log(lam.stable.bm)	
    
    # Filling in of result matrix 
    Res.p.est[k,i] <- p.est
    Res.p.est[k,i+2] <- lam.stable.bm
    Res.p.est[k,i+4] <- R0.stable.bm
    Res.p.est[k,i+6] <- T.stable.bm
  }
}

Res.p.est
```


```{r}
#============================================================================# 
#  Plot: Simulated Lambda, R0 and T with varying p.est (see Figure 4)
#============================================================================# 


win.graph
par(mfrow=c(1,3), mar=c(3,3,1,2)+0.1, bty="l",pty="s", cex.main=1, cex.axis=1, cex.lab=1, tck=0.02, mgp=c(2, 0.3 ,0)) ;

plot(Res.p.est[,1],Res.p.est[,3],type="n",xlab=expression(paste(italic(p)[e])),ylab=expression(lambda))
lines(Res.p.est[,1],Res.p.est[,3],lty=1)
lines(Res.p.est[,1],Res.p.est[,4],lty=2)
points(p.est.FU,1.05, pch=19, cex=2.0); points(p.est.SP,1.17, pch=1, cex=2.0); 
legend(0.0006,1,c("FU", "SP"),pch=c(19,1),lty=c(1,2),bty="n",xjust=0,cex=1.5)

plot(Res.p.est[,1],Res.p.est[,5],type="n",xlab=expression(paste(italic(p)[e])),ylab=expression(paste(italic(R[0]))))
lines(Res.p.est[,1],Res.p.est[,5],lty=1)
lines(Res.p.est[,1],Res.p.est[,6],lty=2)
points(p.est.FU,1.67, pch=19, cex=2.0); points(p.est.SP,4.97, pch=1, cex=2.0); 

plot(Res.p.est[,1],Res.p.est[,7],type="n",xlab=expression(paste(italic(p)[e])),ylab=expression(italic(T)),ylim=c(10,13))
lines(Res.p.est[,1],Res.p.est[,7],lty=1)
lines(Res.p.est[,1],Res.p.est[,8],lty=2)
points(p.est.FU,10.82, pch=19, cex=2.0); points(p.est.SP,10.37, pch=1, cex=2.0);
```


```{r}
#============================================================================# 
#  Bootstrap lambda, R0 and generation time (see Appendix S4)
#============================================================================# 


n.boot=5000
dem.stats=array(NA,dim=c(n.boot,3,2))
boot.ESS=array(NA,dim=c(n.boot,2))

M.tl=array(0,dim=c(2*n,2*n))

for(b.samp in 1:n.boot){
  
  #growth
  
  size.t=size.t.all[flow.all==0]
  size.t1=size.t1.all[flow.all==0]
  site.s=site.all[flow.all==0]
  test=complete.cases(size.t,size.t1,site.s)
  size.t=size.t[test]
  size.t1=size.t1[test]
  site.s=site.s[test]
  sample.boot=c(sample(1:735,replace=T),735+sample(1:357,replace=T))
  size.t.boot=size.t[sample.boot]
  size.t1.boot=size.t1[sample.boot]
  fit.grow.gls.boot<-gls(size.t1.boot~site.s+size.t.boot-1,na.action=na.omit,weight=varExp(form=~fitted(.)|site.s),method="ML");
  g.intercepts.boot=fit.grow.gls.boot$coef[1:2]
  g.slopes.boot=rep(fit.grow.gls.boot$coef[3],2)
  var.exp.coef.boot=fit.grow.gls.boot$modelStruct$varStruct  
  sigma.g.boot=fit.grow.gls.boot$sigma
  
  #survival and flowering
  
  sample.boot=c(sample(1:827,replace=T),827+sample(1:746,replace=T))
  size.t.boot=size.t.all[sample.boot]
  flow.all.boot=flow.all[sample.boot]
  surv.all.boot=surv.all[sample.boot]
  fit.flow.boot=glm(flow.all.boot~site.all*size.t.boot-1,family=binomial)
  f.intercepts.boot=fit.flow.boot$coef[1:2]
  f.slopes.boot=c(fit.flow.boot$coef[3],fit.flow.boot$coef[3]+fit.flow.boot$coef[4])
  fit.surv.boot=glm(surv.all.boot~site.all*size.t.boot-1,family=binomial)
  s.intercepts.boot=fit.surv.boot$coef[1:2]
  s.slopes.boot=c(fit.surv.boot$coef[3],fit.surv.boot$coef[3]+fit.surv.boot$coef[4])
  
  #fecundity
  
  sample.boot=c(sample(1:25,replace=T),25+sample(1:28,replace=T))
  size.t.f.boot=size.t.f[sample.boot]
  si.t1.f.boot=si.t1.f[sample.boot]
  fit.fec.boot=lm(log(si.t1.f.boot)~site.t.f+size.t.f.boot-1)
  
  #seedlings
  
  sample.boot=c(sample(1:573,replace=T),573+sample(1:123,replace=T))
  seedlings.size.t.boot=seedlings.size.t[sample.boot]
  fit.seedlings.boot=lm(seedlings.size.t.boot~seedlings.site-1)
  
  #p.est
  
  sample.boot=c(sample(1:70,replace=T),70+sample(1:42,replace=T))	
  p.est.seeds.t.boot=p.est.seeds.t[sample.boot]
  p.est.seedlings.boot=p.est.seedlings[sample.boot]
  est.p.est.boot= sapply(split(p.est.seedlings.boot,p.est.site),sum)/sapply(split(p.est.seeds.t.boot,p.est.site),sum)
  
  
  for(i in 1:2){
    p.vec[1]<- s.intercepts.boot[i]				
    p.vec[2]<- s.slopes.boot[i]				
    p.vec[3]<- f.intercepts.boot[i]				
    p.vec[4]<- f.slopes.boot[i]				
    p.vec[5]<- g.intercepts.boot[i]				
    p.vec[6]<- g.slopes.boot[i]				
    p.vec[7]<- sigma.g.boot^2				
    p.vec[8]<- fit.fec.boot$coef[i]  			
    p.vec[9]<- fit.fec.boot$coef[3]		 		
    p.vec[10]<- fit.seedlings.boot$coef[i]			
    p.vec[11]<- summary(fit.seedlings.boot)$sigma^2		
    p.vec[12]<- var.exp.coef.boot[i]	
    
    if(i==1) p.est= est.p.est.boot[1] else p.est=est.p.est.boot[2] 
    
    P<-h*t(outer(y,y,pxy,params=p.vec))
    B<-h*t(outer(y,y,fxy,params=p.vec))
    
    M.tl=array(0,dim=c(2*n,2*n))
    M.tl[1:n,1:n]=P
    M.tl[1:n,(n+1):(2*n)]=B
    M.tl[(n+1):(2*n),1:n]=diag(n)
    
    lam=Re(eigen(M.tl)$values[1]);
    
    #R0
    
    M.P=array(0,dim=c(2*n,2*n))
    M.B=array(0,dim=c(2*n,2*n))
    
    M.P[1:n,1:n]=P
    M.P[(n+1):(2*n),1:n]=diag(n)
    
    M.B[1:n,(n+1):(2*n)]=B
    
    N<-solve(diag(2*n)-M.P);
    R<- M.B %*% N
    R0<-Re(eigen(R)$values[1]);
    
    #generation time
    
    T=log(R0)/log(lam)
    boot.data=c(lam,R0,T)
    
    dem.stats[b.samp,,i]=boot.data
    
    if(any(!is.na(boot.data))){ 
      boot.ESS[b.samp,i]<-optimize(R0.betas,c(-150,10),maximum=T,tol=0.01)$maximum
    } else boot.ESS[b.samp,i]=NA
  }
  cat("sample ",b.samp,"\n")
}	

getStats=function(x){
  ci.normal.app=c(mean(x)-1.96*sd(x),mean(x)+1.96*sd(x))
  res=c(mean(x,na.rm=T),quantile(x,p=c(0.025,0.5,0.975),na.rm=T),ci.normal.app)
  return(res)
}

for(i in 1:2){
  cat("site ",site.code.l[i],"\n")
  print(apply(dem.stats[,,i],2,getStats))
  print(getStats(boot.ESS[,i]))
}
```


```{r}
#============================================================================# 
#  Plot: Bootstrap lambda, R0 and generation time (see Appendix S4)
#============================================================================# 


win.graph()
par(mfrow=c(2,4), mar=c(3,3,1,2)+0.1, bty="l",pty="s", cex.main=1, cex.axis=1, cex.lab=1, tck=0.02, mgp=c(2, 0.3 ,0)) ;

main.titles=c(expression(italic(lambda)),expression(italic(R[0])),"Generation time, T",expression("ESS " * italic(beta * scriptstyle(0))))

for(i in 1:2){
  for(j in 1:3){
    hist(dem.stats[,j,i][dem.stats[,j,i]<30],xlab=main.titles[j],col="grey",main="")
    abline(v=mean(dem.stats[,j,i],na.rm=T))
    abline(v=median(dem.stats[,j,i],na.rm=T),col="blue")
    abline(v=quantile(dem.stats[,j,i],p=0.025,na.rm=T),col="red")
    abline(v=quantile(dem.stats[,j,i],p=0.975,na.rm=T),col="red")
  }
  
  hist(boot.ESS[,i],col="grey",xlab=main.titles[4],main="")
  abline(v=mean(boot.ESS[,i],na.rm=T))
  abline(v=median(boot.ESS[,i],na.rm=T),col="blue")
  abline(v=quantile(boot.ESS[,i],p=0.025,na.rm=T),col="red")
  abline(v=quantile(boot.ESS[,i],p=0.975,na.rm=T),col="red")
  abline(v=f.intercepts[i],col="green",lwd=2)
}

lam.diff=dem.stats[,1,1]-dem.stats[,1,2]
mean(lam.diff,na.rm=T)
quantile(lam.diff,p=c(0.025,0.5,0.975),na.rm=T)
R0.diff=dem.stats[,2,1]-dem.stats[,2,2]
mean(R0.diff,na.rm=T)
quantile(R0.diff,p=c(0.025,0.5,0.975),na.rm=T)
T.diff=dem.stats[,3,1]-dem.stats[,3,2]
mean(T.diff,na.rm=T)
quantile(T.diff,p=c(0.025,0.5,0.975),na.rm=T)
```




